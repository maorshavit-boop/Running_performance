{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "532f8dd1-8ab0-4ff1-8f8f-3429a449870d",
   "metadata": {},
   "source": [
    "## Running Performance Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac717c18-4a07-46d4-8ed0-a81d91dac2ed",
   "metadata": {},
   "source": [
    "**1. Problem Statement -**  \n",
    "    - <u>Objective:</u> Classify runners into perforance tiers (Beginner / Intermediate / Advanced) based on running metrics. Compare between Clustering to true labels.  \n",
    "**2. Data Collection -**  \n",
    "    - based on friends' running data (Garmin Connect, RunKeeper, Apple Watch, Nike run club, Strava)  \n",
    "    - Kaggle - \"Running Log Insight\", \"Running races from Strava\", \"strava-data\"  \n",
    "**3. Method**  \n",
    "    - Gather the datasets and create a median run for each runner, than use the running metric chosen and run the model.  \n",
    "    - Using Riegel formula - https://trainasone.com/ufaq/riegels-formula/ to create a custom running metric.   \n",
    "    - Splitting the data to train and test by using traintestsplit function (splits randomly the data to train split and test split, sizes can be determine by the user) and Cross Validation (divides the data to multiple 'folds', every time using different 'fold' as the test split and running the model than aggregate the model results and returns their\n",
    "    &nbsp;&nbsp; average).     \n",
    "    - Classification models - Decision Tree, Logistic Regression, Random Forest, Gradient Boosting.  \n",
    "    - Clustering model - K-means  \n",
    "**4. Measuring Model Performance**  \n",
    "    - **Common classification metrics:**  \n",
    "        &nbsp;&nbsp;&nbsp;- <u>Accuracy</u> - Measures the ratio of True classifications. Formula - (TP + TN)/ (TP + TN + FP + FN)  \n",
    "        &nbsp;&nbsp;&nbsp;- <u>Precision</u> - Measures the ratio of True Positive out of all the positives classifications in the model. <br>&nbsp;&nbsp;&nbsp;&nbsp;Formula - TP/(TP + FP)  \n",
    "        &nbsp;&nbsp;&nbsp;- <u>Recall</u> - Measures the ratio of True Positive out of all real positives. Formula - TP/(TP + FN)  \n",
    "        &nbsp;&nbsp;&nbsp;- <u>F1 Score</u> - Harmonic mean of its precision and recall, providing a single value that balances both - 2 X Precision &nbsp;&nbsp;&nbsp; X Recall / (Precision + Recall)  \n",
    "    - **Decision Tree metrics:**  \n",
    "        &nbsp;&nbsp;&nbsp;- <u>Gini</u> - Measures the impurity of data within a decision tree node when 0 means that the node is pure (contains &nbsp;&nbsp;&nbsp;only elements of a single class) and Higher values means that the node is impure (has a more mixed distribution &nbsp;&nbsp;&nbsp;of classes)   \n",
    "    - **Classification Summaries:**  \n",
    "        &nbsp;&nbsp;&nbsp;- <u>Support</u> - Number of actual occurrences of the class in the specified dataset   \n",
    "        &nbsp;&nbsp;&nbsp;- <u>Macro Avg</u> - The unweighted average of the per-class metrics. It calculates the metric for each class and then &nbsp;&nbsp;&nbsp;takes a simple arithmetic mean.  \n",
    "        &nbsp;&nbsp;&nbsp;- <u>Weighted Avg</u> - The average of the per-class metrics, weighted by the support for each class.  \n",
    "    - **Common Clustering metrics:**  \n",
    "    &nbsp;&nbsp;&nbsp;- **Internal Clustering Validation Metrics**  \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- <u>Interia</u> - The sum of the squared distances between each data point and the centroid of its assigned cluster. It measures how 'tight' or 'compact' the class is. A &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lower interia value indicates that the data points are closer to their cluster centroids, meaning the clusters are more dense and well-defined. As you increase the &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number of clusters (K), the inertia will always decrease because each point will be closer to a centroid.  \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- <u>Davies-Bouldin score</u> - The average similarity measure of each cluster with its most similar cluster. Similarity is measured as a ratio of within-cluster distances to &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;between-cluster distances. A lower score is better and the minimum score is 0. A lower score indicates that the clusters are more compact and better separated from &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;each other.   \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- <u>Silhouette score</u> - The Silhouette score provides a more formal way to evaluate the quality of your clustering. It measures how similar an object is to its own &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cluster (cohesion) compared to other clusters (separation). The score is calculated for each data point and then averaged. The score range is between (-1,1) when 1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;means that the data point is well-matched to its own cluster and well-separated from neighboring clusters, 0 means that the data point is on or very close to the &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;decision boundary between two clusters and -1 means that the data point is likely Assigned to the wrong cluster.  \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- <u>Calinski-Harabasz Index</u> (Variance Ratio Criterion) - This score is a ratio of the between-cluster dispersion mean and the within-cluster dispersion mean. A higher score &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;is better it shows that the clusters are dense and well seperated.  \n",
    "    &nbsp;&nbsp;&nbsp;- **External Clustering Validation Metrics** - These are used when you have a dataset with known class labels and you want to see how well your clustering algorithm can &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;recreate those classes.   \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- <u>Adjusted Rand Index (ARI)</u> - It measures the similarity between two clusterings (your predicted clusters and the true labels), while the \"Adjusted\" version corrects for &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chance. The score ranges from -1 to 1. A score of 1 indicates perfect agreement. A score of 0 indicates a random assignment. A negative score indicates that the &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;assigment was even worse than random assignment.  \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- <u>Homogeneity</u> - Measures if each cluster contains only data points of a single class.  \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- <u>Completeness</u> - Measures if all data points of a given class are in the same cluster.  \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- <u>V-measure</u> - The harmonic mean of homogeneity and completeness, providing a single score that balances both. The score ranges from 0 to 1, with 1 being the best.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; These metrics are based on conditional entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a7e58-48d5-458a-9604-82cc3636913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict, learning_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc,mean_squared_error,accuracy_score,precision_score,recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import QuantileTransformer,PowerTransformer,RobustScaler,StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, adjusted_rand_score, v_measure_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '2'\n",
    "print(\"âœ… All libraries are working!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8322399c-eddb-4f32-9fd8-7e847e503239",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"4\"  # Adjust to your physical core count\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228958c-8941-4f3f-a03c-db1fa3038ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jeffreybraun/running-log-insight\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "path1 = kagglehub.dataset_download(\"olegoaer/running-races-strava\")\n",
    "print(\"Path to dataset files:\", path1)\n",
    "\n",
    "path2 = kagglehub.dataset_download(\"ayushtankha/nike-run-club-data-200-runs\")\n",
    "print(\"Path to dataset files:\", path2) ##TCX files, irrelevant\n",
    "\n",
    "path3 = kagglehub.dataset_download(\"ajitjadhav1/strava-running-activity-data\")\n",
    "print(\"Path to dataset files:\", path3) ## No HR\n",
    "\n",
    "path4 = kagglehub.dataset_download(\"purpleyupi/strava-data\")\n",
    "print(\"Path to dataset files:\", path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d4f754-e31a-4343-8351-5a64229c0543",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Functions\n",
    "def filter_columns(dfs, columns, names=None):\n",
    "    new_dfs = []\n",
    "    for i, df in enumerate(dfs):\n",
    "        keep = [c for c in columns if c in df.columns]\n",
    "        if names:\n",
    "            missing = [c for c in columns if c not in df.columns]\n",
    "            if missing:\n",
    "                print(f\"{names[i]} is missing columns: {missing}\")\n",
    "        new_dfs.append(df[keep])\n",
    "    return new_dfs\n",
    "def pace_to_float(pace):\n",
    "    if isinstance(pace, str) and \":\" in pace:\n",
    "        minutes, seconds = pace.split(\":\")\n",
    "        return int(minutes) + int(seconds)/60\n",
    "    if isinstance(pace, datetime.time):\n",
    "        return pace.minute + pace.second / 60\n",
    "    if isinstance(pace, datetime.timedelta):\n",
    "        return pace.total_seconds() / 60\n",
    "    try:\n",
    "        return float(pace)\n",
    "    except:\n",
    "        return None\n",
    "def time_to_minutes(t):\n",
    "    if isinstance(t, str) and \":\" in t:\n",
    "        parts = t.split(\":\")\n",
    "        try:\n",
    "            if len(parts) == 3:  # hh:mm:ss\n",
    "                h, m, s = parts\n",
    "                return int(h) * 60 + int(m) + float(s) / 60\n",
    "            elif len(parts) == 2:  # mm:ss\n",
    "                m, s = parts\n",
    "                return int(m) + float(s) / 60\n",
    "            else:\n",
    "                return float(t)\n",
    "        except ValueError:\n",
    "            return None \n",
    "    if isinstance(t, datetime.timedelta):\n",
    "        return t.total_seconds() / 60\n",
    "    if isinstance(t, datetime.time):\n",
    "        return t.hour*60 + t.minute + t.second / 60\n",
    "    else:\n",
    "        return float(t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bff9283-3d59-4ed7-ad93-67b7a595801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maor = pd.read_csv(\"C:\\\\Users\\\\maors\\\\Maor's studies\\\\datasets\\\\maor's_data.csv\")\n",
    "ely = pd.read_excel(\"C:/Users/maors/Maor's studies/datasets/Ely's_data(no_HR).xlsx\")\n",
    "shapira = pd.read_excel(\"C:/Users/maors/Maor's studies/datasets/shapira's_data.xlsx\")\n",
    "someone = pd.read_csv(\"C:/Users/maors/Maor's studies/datasets/activity_log.csv\")\n",
    "franco = pd.read_excel(\"C:/Users/maors/Maor's studies/datasets/franco's_data.xlsx\")\n",
    "danieli = pd.read_excel(\"C:/Users/maors/Maor's studies/datasets/ido's_data.xlsx\")\n",
    "ehud = pd.read_excel(\"C:/Users/maors/Maor's studies/datasets/ehud's_data.xlsx\")\n",
    "#print(maor.head())\n",
    "columns = [\"Distance\", \"Time\", \"Avg HR\", \"Avg Pace\"]\n",
    "dfs = [maor, ely, shapira, someone, franco, danieli, ehud]\n",
    "names = [\"maor\", \"ely\", \"shapira\", \"someone\", \"franco\", \"danieli\",\"ehud\"]\n",
    "dfs = filter_columns(dfs, columns, names)\n",
    "maor, ely, shapira, someone, franco, danieli, ehud = dfs\n",
    "print(shapira.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6120aa72-a9cd-43ac-87a3-522afe8aeb29",
   "metadata": {},
   "source": [
    "**Running metrics for Classification**  \n",
    "I have tried to use a general metric that ignores Vo2 Max (the most common metric for running performance) because I couldn't get that information from all runners. The metric is being calculated for each run by the next formula:    \n",
    "**GRPS= (1/NormalizedÂ Pace)/NormalizedÂ Heart rate** (Low pace --> good score, GRPS stands for General running performance score). This metric is very similar to the Riegel model which is used to predict race times for runners by extrapolating from a known race time and distance the only addition is dividing by the normalized HR so that my formula will consider the runner Avg HR.     \n",
    "Normalized Pace will be calculated by the 10K Equivalent Pace for each run:  \n",
    "**T2 = T1(D2/D1)^c**  \n",
    "    - T1 - Time for Run 1    \n",
    "    - T2 - Predicted time for run 2  \n",
    "    - D1 - Distance for run 1  \n",
    "    - D2 - Distance for run 2 (based on the 'standard' - 10K)  \n",
    "    - C - A constant - 1.06 (It is based on a well-established model (like the Riegel or Cameron models) that has been validated by analyzing the performance of thousands of runners across different distance)    \n",
    "This effectively accounts for the factor of distance and allows you to compare the \"effort\" of a 10K race to an easy long run/shorter runs on the same scale.\n",
    "**Normalized Pace = T2/D2**\n",
    "Normalized Heart Rate will be calculated by this formula:  \n",
    "**Normalized HR = Avg HR / Benchmark HR**  \n",
    "    - Benchmark HR - 220 - age (Simple but may be inaccurate). For simplification I used 195 as benchmark HR (all the participants are between the age 23-26)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeeab7e-ed7b-41f0-88d4-37db398ae3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dfs)):\n",
    "    #df[\"Avg Pace\"] = df[\"Avg Pace\"].apply(pace_to_float)\n",
    "    df = dfs[i]\n",
    "    df['Distance'] = df['Distance'].replace(0.0, np.nan)\n",
    "    df['Avg HR'] = pd.to_numeric(df['Avg HR'], errors='coerce')\n",
    "    df = df.loc[df['Distance'] < 50] #handles outliers in the data\n",
    "    df.loc[:, \"Time\"] = df[\"Time\"].apply(time_to_minutes).astype(float) #Changes the time to a format which is easier to conevrt to float later on\n",
    "    df = df.dropna(subset=['Time', 'Distance']) # Drop rows with missing values\n",
    "    df[\"Calculated pace\"] = df[\"Time\"] / df[\"Distance\"]\n",
    "    dfs[i] = df\n",
    "    #print(df.describe())\n",
    "    #print(df.info())\n",
    "maor, ely, shapira, someone, franco, danieli, ehud = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1660c5f-e887-454a-92aa-21d2a20e5b3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GRPS calculation\n",
    "for i in range(len(dfs)):\n",
    "    df = dfs[i]\n",
    "    df[\"T2\"] = df[\"Time\"] * (10/df[\"Distance\"]) ** 1.06\n",
    "    df[\"Normalized_HR\"] = df[\"Avg HR\"] / 195\n",
    "    df[\"GRPS\"] = ((10 / df[\"T2\"]) / df[\"Normalized_HR\"]) * 100\n",
    "    dfs[i] = df\n",
    "maor, ely, shapira, someone, franco, danieli, ehud = dfs\n",
    "maor_GRPS_score = maor[\"GRPS\"].median() \n",
    "ely_GRPS_score = ely[\"GRPS\"].median() \n",
    "someone_GRPS_score = someone[\"GRPS\"].median() \n",
    "shapira_GRPS_score = shapira[\"GRPS\"].median() \n",
    "smeone_GRPS_score = someone[\"GRPS\"].median() \n",
    "franco_GRPS_score = franco[\"GRPS\"].median() \n",
    "danieli_GRPS_score = danieli[\"GRPS\"].median() \n",
    "ehud_GRPS_score = ehud[\"GRPS\"].median()\n",
    "print(f\"Maor's GRPS score:, {maor_GRPS_score:.3f}\")\n",
    "print(f\"Ely's GRPS score:, {ely_GRPS_score:.3f}\")\n",
    "print(f\"Someone's GRPS score:, {someone_GRPS_score:.3f}\")\n",
    "print(f\"Shapira's GRPS score:, {shapira_GRPS_score:.3f}\")\n",
    "print(f\"Franco's GRPS score:, {franco_GRPS_score:.3f}\")\n",
    "print(f\"Danieli's GRPS score:, {danieli_GRPS_score:.3f}\")\n",
    "print(f\"Ehud's GRPS score:, {ehud_GRPS_score:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16402741-e6bd-4071-9c00-06b749a0644d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creatimg a median run Data frame with synthetic data\n",
    "median_runs = []\n",
    "for i, df in enumerate(dfs):\n",
    "    median_time = df[\"Time\"].median()\n",
    "    median_distance = df[\"Distance\"].median()\n",
    "    median_Avg_HR = df[\"Avg HR\"].median()\n",
    "    median_Calculated_pace = df[\"Calculated pace\"].median()\n",
    "    median_GRPS = df[\"GRPS\"].median()\n",
    "    \n",
    "    median_df = pd.DataFrame([{\n",
    "        \"Runner\": names[i],\n",
    "        \"Median Time\": median_time,\n",
    "        \"Median Distance\": median_distance,\n",
    "        \"Median Avg HR\": median_Avg_HR,\n",
    "        \"Median Calculated Pace\": median_Calculated_pace,\n",
    "        \"Median GRPS Score\": median_GRPS\n",
    "    }])\n",
    "    median_runs.append(median_df)\n",
    "final_df = pd.concat(median_runs, ignore_index=True)\n",
    "#print(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bf88b0-128f-4258-92e6-67c007f40f8b",
   "metadata": {},
   "source": [
    "**Using 2 datasets found on Kaggle. The first one with a total of 116 runners with results of 42000 races, the second one with 165 regular runners.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26306b-8165-4766-9737-0f10d3bd74c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strava_df = pd.read_excel(\"C:\\\\Users\\\\maors\\\\Maor's studies\\\\datasets\\\\raw-data-kaggle.xlsx\")\n",
    "\n",
    "# If the data is stored in a single column as semicolon-separated strings, split it\n",
    "if strava_df.shape[1] == 1 and strava_df.columns[0] == 'athlete;gender;timestamp;distance (m);elapsed time (s);elevation gain (m);average heart rate (bpm)':\n",
    "    strava_df = strava_df.iloc[:, 0].str.split(\";\", expand=True) # Split the single column into multiple columns\n",
    "    strava_df.columns = [\"athlete\", \"gender\", \"timestamp\", \"distance (m)\",\"elapsed time (s)\", \"elevation gain (m)\", \"average heart rate (bpm)\"]\n",
    "\n",
    "strava_df[\"timestamp\"] = pd.to_datetime(strava_df[\"timestamp\"], dayfirst=True)\n",
    "strava_df[\"distance (m)\"] = pd.to_numeric(strava_df[\"distance (m)\"], errors='coerce') #If you find a value that canâ€™t be converted, donâ€™t crash â€” just turn it into NaN\n",
    "strava_df[\"elapsed time (s)\"] = pd.to_numeric(strava_df[\"elapsed time (s)\"], errors='coerce')\n",
    "strava_df[\"elevation gain (m)\"] = pd.to_numeric(strava_df[\"elevation gain (m)\"], errors='coerce')\n",
    "strava_df[\"average heart rate (bpm)\"] = pd.to_numeric(strava_df[\"average heart rate (bpm)\"], errors='coerce')\n",
    "strava_df[\"Distance\"] = strava_df[\"distance (m)\"] / 1000\n",
    "strava_df[\"Time\"] = strava_df[\"elapsed time (s)\"] / 60\n",
    "strava_df[\"Calculated Pace\"] = strava_df[\"Time\"] / strava_df[\"Distance\"]\n",
    "strava_df.drop(columns = [\"gender\",\"elevation gain (m)\",\"distance (m)\", \"timestamp\", \"elapsed time (s)\"], inplace = True)\n",
    "strava_df.rename(columns={\"average heart rate (bpm)\": \"Avg HR\"}, inplace=True)\n",
    "strava_df.rename(columns={\"athlete\": \"Runner\"}, inplace=True)\n",
    "\n",
    "#print(strava_df.head())\n",
    "median_strava_runs = strava_df.groupby(\"Runner\", as_index=False)[[\"Avg HR\", \"Distance\", \"Time\", \"Calculated Pace\"]].median()\n",
    "median_strava_runs[\"Avg HR\"] = strava_df.groupby(\"Runner\")[\"Avg HR\"].transform(lambda x: x.fillna(x.median()))\n",
    "median_strava_runs[\"T2\"] = median_strava_runs[\"Time\"] * (10 / median_strava_runs[\"Distance\"]) ** 1.06\n",
    "median_strava_runs[\"Normalized_HR\"] = median_strava_runs[\"Avg HR\"] / 195\n",
    "median_strava_runs[\"GRPS score\"] = (10 / median_strava_runs[\"T2\"]) / median_strava_runs[\"Normalized_HR\"] * 100\n",
    "median_strava_runs.drop(columns = [\"Normalized_HR\",\"T2\"], inplace = True)\n",
    "#print(median_strava_runs.sample(7))\n",
    "#print(median_strava_runs.info())\n",
    "#print(median_strava_runs.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f7a8a-dc1f-48dd-9740-d582dc60b841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strava2_df = pd.read_csv(\"C:\\\\Users\\\\maors\\\\.cache\\\\kagglehub\\\\datasets\\\\purpleyupi\\\\strava-data\\\\versions\\\\2\\\\strava_full_data.csv\")\n",
    "strava2_df.drop(columns = [\"kudos_count\",\"start_date_local\",\"type\",\"elev_high\", \"max_heartrate\", \"max_speed\",\"elapsed_time\",\"total_elevation_gain\"], inplace = True)\n",
    "#strava2_df[\"distance\"] = pd.to_numeric(strava2_df[\"distance\"], errors='coerce') #If you find a value that canâ€™t be converted, donâ€™t crash â€” just turn it into NaN\n",
    "strava2_df[\"moving_time\"] = strava2_df[\"moving_time\"].apply(time_to_minutes).astype(float)\n",
    "strava2_df[\"average_heartrate\"] = pd.to_numeric(strava2_df[\"average_heartrate\"], errors='coerce')\n",
    "strava2_df[\"distance\"] = strava2_df[\"distance\"] / 1000\n",
    "strava2_df.rename(columns={\"distance\": \"Distance\"}, inplace=True)\n",
    "strava2_df.rename(columns={\"moving_time\": \"Time\"}, inplace=True)\n",
    "strava2_df[\"Calculated Pace\"] = strava2_df[\"Time\"] / strava2_df[\"Distance\"]\n",
    "strava2_df.rename(columns={\"average_heartrate\": \"Avg HR\"}, inplace=True)\n",
    "strava2_df.rename(columns={\"Column1\": \"Runner\"}, inplace=True)\n",
    "#print(strava_df.head())\n",
    "median_strava2_runs = strava2_df.groupby(\"Runner\", as_index=False)[[\"Avg HR\", \"Distance\", \"Time\", \"Calculated Pace\"]].median()\n",
    "median_strava2_runs = median_strava2_runs.dropna(subset=[\"Avg HR\"])\n",
    "median_strava2_runs[\"T2\"] = median_strava2_runs[\"Time\"] * (10 / median_strava2_runs[\"Distance\"]) ** 1.06\n",
    "median_strava2_runs[\"Normalized_HR\"] = median_strava2_runs[\"Avg HR\"] / 195\n",
    "median_strava2_runs[\"GRPS score\"] = (10 / median_strava2_runs[\"T2\"]) / median_strava2_runs[\"Normalized_HR\"] * 100\n",
    "median_strava2_runs.drop(columns = [\"Normalized_HR\",\"T2\"], inplace = True)\n",
    "median_strava2_runs = median_strava2_runs.loc[median_strava2_runs['GRPS score'] < 35] #handles outliers in the data\n",
    "median_strava2_runs = median_strava2_runs.loc[median_strava2_runs['Calculated Pace'] < 9] #handles outliers in the data\n",
    "#print(median_strava2_runs.sample(7))\n",
    "#print(median_strava2_runs.info())\n",
    "#print(median_strava2_runs.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f1989-bcbb-46c9-abb5-07f4449867de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_strava = pd.concat([median_strava_runs, median_strava2_runs], ignore_index = True)\n",
    "final_strava.rename(columns={\"Avg HR\": \"Median Avg HR\"}, inplace=True)\n",
    "final_strava.rename(columns={\"Distance\": \"Median Distance\"}, inplace=True)\n",
    "final_strava.rename(columns={\"Time\": \"Median Time\"}, inplace=True)\n",
    "final_strava.rename(columns={\"Calculated Pace\": \"Median Calculated Pace\"}, inplace=True)\n",
    "final_strava.rename(columns={\"GRPS score\": \"Median GRPS Score\"}, inplace=True)\n",
    "final_df = pd.concat([final_strava, final_df], ignore_index = True)\n",
    "final_df[\"Runner_Class\"] = pd.qcut(final_df[\"Median GRPS Score\"], q=[0, 0.30, 0.80, 1], labels=[\"Beginner\", \"Intermediate\", \"Advanced\"])\n",
    "#print(final_df.tail(7))\n",
    "#print(final_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15091a02-6a99-4477-a8e4-b300e87f167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.loc[final_df['Median Time'] < 150]\n",
    "final_df = final_df.loc[final_df['Median Calculated Pace'] < 9.5]\n",
    "print(final_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b422fc-7a29-487e-b895-6af17afc6679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_cols = final_df.select_dtypes(include=np.number)\n",
    "corr_mat = numeric_cols.corr()\n",
    "print(sns.heatmap(corr_mat, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7b3fe-2e00-4260-9929-97307965930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner_classes = [\"Advanced\", \"Intermediate\", \"Beginner\"]\n",
    "colors = ['tab:green', 'tab:orange', 'tab:blue']\n",
    "labels = ['Advanced', 'Intermediate', 'Beginner']\n",
    "numeric_cols = final_df.select_dtypes(include=np.number).columns.tolist()\n",
    "num_plots = len(numeric_cols)\n",
    "num_cols = 3\n",
    "num_rows = (num_plots + num_cols - 1) // num_cols\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    ax = axes[i]\n",
    "    data = [final_df[final_df['Runner_Class'] == cls][col] for cls in runner_classes]\n",
    "    ax.hist(data, bins=15, stacked=True, color=colors, label=labels, alpha=0.8)\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Count')\n",
    "    if i == 0:\n",
    "        ax.legend()\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9092144-de74-4197-b08a-f919dfee98b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df_model = final_df.drop(columns = [\"Median GRPS Score\"])\n",
    "train_split, test_split = train_test_split(final_df_model, test_size = 0.2, random_state = 42, shuffle = True) \n",
    "df_train_features = train_split\n",
    "df_test_features = test_split\n",
    "df_train_target = df_train_features[\"Runner_Class\"]\n",
    "df_test_target = df_test_features[\"Runner_Class\"]\n",
    "#print(df_train_features.info())\n",
    "#print(df_test_features)\n",
    "#print(df_train_target)\n",
    "#print(df_test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee813c8-3108-48fe-8073-19258a0a1567",
   "metadata": {},
   "source": [
    "**Exploring the features: Distance, Calculated pace, avg HR and GRPS vs Runner Class where (1 = Beginner, 2 = Intermediate, 3 = Advanced)**  \n",
    "I didn't use Median Time because it and Median Distance are extremly high correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924454bc-e0a7-4773-b11c-f3530db9a04e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculated Pace and Avg HR in correlation with Runner Class \n",
    "plt.figure(figsize=(8,6)) \n",
    "sns.scatterplot(data=final_df_model, x=\"Median Calculated Pace\", y=\"Median Avg HR\", hue = \"Runner_Class\" )\n",
    "plt.title(\"Median Calculated Pace vs Median Avg HR\")\n",
    "plt.xlabel(\"Median Calculated Pace\")\n",
    "plt.ylabel(\"Median Avg HR\")\n",
    "tick_locations = np.arange(4, 10, 0.5)\n",
    "tick_y_locations = np.arange(110,190,5)\n",
    "plt.xticks(tick_locations)\n",
    "plt.yticks(tick_y_locations)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff807be-2321-4ec8-97fc-9aeadae1def1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Distance and Pace in correlation with Runner Class \n",
    "plt.figure(figsize=(8,6)) \n",
    "sns.scatterplot(data=final_df_model, x=\"Median Distance\", y=\"Median Calculated Pace\", hue = \"Runner_Class\" )\n",
    "plt.title(\"Median Distance vs Median Calculated Pace\")\n",
    "plt.xlabel(\"Median Distace\")\n",
    "plt.ylabel(\"Median Calculated Pace\")\n",
    "tick_locations = np.arange(0, 21, 3)\n",
    "tick_y_locations = np.arange(4,10,0.5)\n",
    "plt.xticks(tick_locations)\n",
    "plt.yticks(tick_y_locations)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df64b3-3680-49f5-915c-82fe3463cde9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Avg HR and Distacne in correlation with Runner Class\n",
    "plt.figure(figsize=(8,6)) \n",
    "sns.scatterplot(data=final_df_model, x=\"Median Distance\", y=\"Median Avg HR\", hue = \"Runner_Class\" )\n",
    "plt.title(\"Median Distacne vs Median Avg HR\")\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Median Avg HR\")\n",
    "tick_locations = np.arange(1, 21, 2)\n",
    "tick_y_locations = np.arange(110,190,5)\n",
    "plt.xticks(tick_locations)\n",
    "plt.yticks(tick_y_locations)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdc098c-6277-4497-b861-9bb05850c04e",
   "metadata": {},
   "source": [
    "**1st classification method - Manual Desicion Tree**  \n",
    "We can infer from the data that there is a clear seperation between pace to the runner class (this might be a problem because it doesn't consider that marathon runners should run slower than 5K) and also that akk the runners who runs less than 8 km (on average) are beginners, with the remainig data (pace between 4.7 to 5.6) I chose to use Disatnce and the Avg HR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd3b1b7-98cf-44c1-a0c7-0db5626c825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_rules(runner_row):\n",
    "    if runner_row[\"Median Calculated Pace\"] >= 6.05:\n",
    "        return \"Beginner\"\n",
    "    elif runner_row[\"Median Calculated Pace\"] <= 5.1:\n",
    "        if runner_row[\"Median Distance\"] >= 13:\n",
    "            return \"Advanced\"\n",
    "        elif runner_row[\"Median Avg HR\"]<= 152:\n",
    "            return \"Advanced\"\n",
    "        else: \n",
    "            return \"Intermediate\"\n",
    "    elif runner_row[\"Median Calculated Pace\"] <=6.05:\n",
    "        if 120 <= runner_row[\"Median Avg HR\"] <= 165:\n",
    "            return \"Intermediate\"\n",
    "        elif runner_row[\"Median Avg HR\"] <= 120:\n",
    "            return \"Advanced\"\n",
    "    return \"Beginner\"\n",
    "    \n",
    "res_test = df_test_features.apply(decision_tree_rules, axis=1)\n",
    "res_train = df_train_features.apply(decision_tree_rules, axis=1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0933faa-ca02-4723-8a93-516311e2c930",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Accuracy test split:\n",
    "result_test = df_test_target == res_test  \n",
    "count_T_and_F = result_test.value_counts()\n",
    "accuracy = count_T_and_F[True] / len(res_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(count_T_and_F)\n",
    "\n",
    "#Accuracy train split:\n",
    "result_train = df_train_target == res_train\n",
    "count_T_and_F = result_train.value_counts()\n",
    "accuracy = count_T_and_F[True] / len(res_train)\n",
    "print(\"Train Accuracy:\", accuracy)\n",
    "print(count_T_and_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263785fc-9a52-4f76-97ba-01a67c092db6",
   "metadata": {},
   "source": [
    "**1st Method Results**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a25d6-ad3a-407e-bee1-d51e4b2c1e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(df_test_target, res_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcfb978-0810-47d1-99f5-344d0363362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cm = ['Advanced', 'Intermediate', 'Beginner']\n",
    "cm_DT_manual = confusion_matrix(df_test_target, res_test, labels=labels_cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_DT_manual, display_labels=labels_cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7bdb43-b3cc-4bb7-b56e-b2e746921b0e",
   "metadata": {},
   "source": [
    "**2nd Classification Method - SKL Decision Tree**  \n",
    "Using the decision tree built in function of SKL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a685e8-a256-49c4-ac84-0a4aec5771c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features_numeric = df_train_features.select_dtypes(include=[int, float])\n",
    "df_test_features_numeric = df_test_features.select_dtypes(include=[int, float])\n",
    "sk_tree = DecisionTreeClassifier(random_state=42, max_leaf_nodes=5)\n",
    "sk_tree.fit(df_train_features_numeric, df_train_target)\n",
    "\n",
    "# Predict\n",
    "y_predict_train_sklearn = sk_tree.predict(df_train_features_numeric)\n",
    "y_predict_test_sklearn = sk_tree.predict(df_test_features_numeric)\n",
    "\n",
    "accuracy_train_sklearn = accuracy_score(df_train_target, y_predict_train_sklearn)\n",
    "accuracy_test_sklearn = accuracy_score(df_test_target, y_predict_test_sklearn)\n",
    "\n",
    "print(\"Sklearn Decision Tree Accuracy on train set:\", accuracy_train_sklearn)\n",
    "print(\"Sklearn Decision Tree Accuracy on test set:\", accuracy_test_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9861e4d5-d271-4ed7-b750-b92b5b3009e1",
   "metadata": {},
   "source": [
    "**2nd Method Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ed403-b780-4a01-a162-204ad6f533c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df_test_target, y_predict_test_sklearn))\n",
    "print(classification_report(df_train_target, y_predict_train_sklearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601a533-eafb-40d4-937d-6a4d8cdfcec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_names = [\"Median Time\", \"Median Distance\", \"Median Avg HR\", \"Median Calculated Pace\", \"Median GRPS score\"]\n",
    "class_names = [\"Beginner\", \"Intermediate\", \"Advanced\"]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(sk_tree,\n",
    "          feature_names=feature_names,\n",
    "          class_names=class_names,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10,\n",
    "          impurity=True,\n",
    "          node_ids=False,\n",
    "          proportion=False,\n",
    "          precision=3)\n",
    "plt.title(\"Improved Decision Tree Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706e4a2-9c92-4d8d-8890-0c38af1381be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_DT_func = confusion_matrix(df_test_target, y_predict_test_sklearn, labels=sk_tree.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_DT_func, display_labels=sk_tree.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed04cb-4d96-4e44-8abf-325fc5c59cab",
   "metadata": {},
   "source": [
    "**3rd Method - Logistic Regression**  \n",
    "Using the built in function of SKL and using Cross Validiation to evaluate the performance of the model on unseen sets of data. We should use cross validation to avoid over-fitting and under-fitting, and to get a more reliable estimate of model perfomance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ce507-c34c-4328-9748-9cb2a19c1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_features_numeric_LR = df_train_features_numeric.drop(columns = [\"Median Time\"])\n",
    "#df_test_features_numeric_LR = df_test_features_numeric.drop(columns = [\"Median Time\"])\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('logreg', LogisticRegressionCV(max_iter=300, random_state=42))])\n",
    "pipe.fit(df_train_features_numeric, df_train_target)\n",
    "y_pred = pipe.predict(df_test_features_numeric)\n",
    "coefficients = pd.DataFrame({'Feature': df_train_features_numeric.columns, 'Coefficient': pipe[1].coef_[0]})\n",
    "print(coefficients)\n",
    "print(\"Intercept:\", pipe[1].intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4ff45-7c4d-4949-a567-e55de8c71a8d",
   "metadata": {},
   "source": [
    "**Scaling the data is crucial in Logistic Regression mainly because we want to avoid from the impact of mismatched scale**  \n",
    "**3rd Method Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff73f5-445e-4181-8bbc-128b0c0a3316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(df_test_target, y_pred))\n",
    "train_pred = pipe.predict(df_train_features_numeric)\n",
    "test_pred = pipe.predict(df_test_features_numeric)\n",
    "train_pred_proba = pipe.predict_proba(df_train_features_numeric)\n",
    "test_pred_proba = pipe.predict_proba(df_test_features_numeric)\n",
    "\n",
    "train_accuracy = accuracy_score(df_train_target, train_pred)\n",
    "test_accuracy = accuracy_score(df_test_target, test_pred) ## accuracy - total of True results out of all results (TP + TN / TP + TN + FP + FN)\n",
    "\n",
    "train_roc_auc = roc_auc_score(df_train_target, train_pred_proba, multi_class='ovr')\n",
    "test_roc_auc = roc_auc_score(df_test_target, test_pred_proba, multi_class='ovr') #roc_AUC - area under the roc curve\n",
    "\n",
    "train_precision = precision_score(df_train_target, train_pred, average='weighted')\n",
    "test_precision = precision_score(df_test_target, test_pred, average='weighted') #Precision - How much of the positive is really positive TP / TP + FP\n",
    "\n",
    "train_recall = recall_score(df_train_target, train_pred, average='weighted')\n",
    "test_recall = recall_score(df_test_target, test_pred, average='weighted') #Recall - how much of the positive we have predicted positive TP / TP + FN\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Train ROC AUC:\", train_roc_auc)\n",
    "print(\"Test ROC AUC:\", test_roc_auc)\n",
    "print(\"Train Precision:\", train_precision)\n",
    "print(\"Test Precision:\", test_precision)\n",
    "print(\"Train Recall:\", train_recall)\n",
    "print(\"Test Recall:\", test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18edbdb2-e2fe-46c0-8688-984e54c1ccaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm_LR = confusion_matrix(df_test_target, test_pred, labels=pipe.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_LR, display_labels=pipe.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a014cc88-12e1-4f39-bc85-0685ece00264",
   "metadata": {},
   "source": [
    "**4th Classification Method - Random Forest** - An ensemble of decision trees. Each tree is trained on a bootstrap sample (random subset with replacement). At each split, only a random subset of features is considered.Final prediction = majority vote (classification) or average (regression). This randomness reduces variance (overfitting), while maintaining low bias.  \n",
    "**Advantages** - Handles nonlinear feature interactions well. Robust to outliers & noise. Provides feature importance.\n",
    "**Cross-val predictions** on training data (for diagnostics) - This process ensures that every data point gets predicted once, but never by a model trained on itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af01d415-5751-4aba-a772-5ff9d20ec239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random forest Pipeline\n",
    "features = final_df_model.select_dtypes(include=[int, float])\n",
    "feature_cols = features.columns.tolist()\n",
    "rf_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"rf\", RandomForestClassifier(\n",
    "        n_estimators=200, max_depth=None, random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_cv = cross_val_predict(rf_pipe, df_train_features_numeric, df_train_target, cv=cv)\n",
    "print(\"CV results:\")\n",
    "print(classification_report(df_train_target, y_pred_cv, digits=3))\n",
    "\n",
    "rf_pipe.fit(df_train_features_numeric, df_train_target)\n",
    "y_pred_test = rf_pipe.predict(df_test_features_numeric)\n",
    "print(\"Test results:\")\n",
    "print(classification_report(df_test_target, y_pred_test, digits=3))\n",
    "\n",
    "train_accuracy = accuracy_score(df_train_target, y_pred_cv)\n",
    "test_accuracy = accuracy_score(df_test_target, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c68c034-14c6-456b-a3c4-39dd3cc52380",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df_test_target, y_pred_test, labels=rf_pipe.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf_pipe.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab2505-4cdd-44ae-b2f3-8750ccbfea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_pipe.named_steps[\"rf\"].feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_cols).sort_values(ascending=False)\n",
    "feat_imp.plot(kind=\"barh\")\n",
    "plt.title(\"Feature Importances (Random Forest)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bc70a-5ba8-44f0-a79a-7a13aaf7b4dd",
   "metadata": {},
   "source": [
    "**Fifth Method - Gradient Boosting** Another ensemble of trees, but instead of training independently (like RF), each new tree is trained to correct the errors of the previous trees.Itâ€™s sequential â†’ learns residuals. The model improves gradually, with a learning rate controlling how much each new tree contributes.  \n",
    "**Advantages** - Typically achieves higher accuracy than Random Forest if tuned well. Handles complex nonlinear interactions. More sensitive to hyperparameters (learning_rate, n_estimators, max_depth). Often best for tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f72d7a0-35bd-4c37-a68a-71acf5151fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient boosting\n",
    "gb_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"gb\", GradientBoostingClassifier(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=3, random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "y_pred_cv = cross_val_predict(gb_pipe, df_train_features_numeric, df_train_target, cv=cv)\n",
    "print(\"CV results (Gradient Boosting):\")\n",
    "print(classification_report(df_train_target, y_pred_cv, digits=3))\n",
    "\n",
    "gb_pipe.fit(df_train_features_numeric, df_train_target)\n",
    "y_pred_test = gb_pipe.predict(df_test_features_numeric)\n",
    "print(\"Test results (Gradient Boosting):\")\n",
    "print(classification_report(df_test_target, y_pred_test, digits=3))\n",
    "\n",
    "train_accuracy = accuracy_score(df_train_target, y_pred_cv)\n",
    "test_accuracy = accuracy_score(df_test_target, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c495b14-2b3e-4886-a039-6e73ed90c13a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df_test_target, y_pred_test, labels=gb_pipe.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gb_pipe.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "importances = gb_pipe.named_steps[\"gb\"].feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_cols).sort_values(ascending=False)\n",
    "feat_imp.plot(kind=\"barh\")\n",
    "plt.title(\"Feature Importances (Gradient Boosting)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc2a38-9322-4758-9dd7-807628a114c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(pipe, X_train, X_test, y_train, y_test, model_name):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Macro F1\": f1_score(y_test, y_pred, average=\"macro\"),\n",
    "        \"Macro Precision\": precision_score(y_test, y_pred, average=\"macro\"),\n",
    "        \"Macro Recall\": recall_score(y_test, y_pred, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "results = []\n",
    "results.append(eval_model(sk_tree, df_train_features_numeric, df_test_features_numeric, df_train_target, df_test_target, \"SKL Decision Tree\"))\n",
    "results.append(eval_model(pipe, df_train_features_numeric, df_test_features_numeric, df_train_target, df_test_target, \"Logistic Regression\"))\n",
    "results.append(eval_model(rf_pipe, df_train_features_numeric, df_test_features_numeric, df_train_target, df_test_target, \"Random Forest\"))\n",
    "results.append(eval_model(gb_pipe, df_train_features_numeric, df_test_features_numeric, df_train_target, df_test_target, \"Gradient Boosting\"))\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cbe5eb-6454-4a91-94cb-38baf0a37f79",
   "metadata": {},
   "source": [
    "**Classification conclusions**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**<u>Model Comparsions</u>**    \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- <u>First Method: Building my own decision tree</u>  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This model demonstrated a mediocre performance on both the train and test sets, with an accuracy between 0.74 and 0.80. The method used to determine the node &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;splits was based on observing the graphs and identifying correlations between the different features and their respective classes.  \n",
    "Â Â Â Â Â Â Â Â  We can see that the model had a slight tendency to classify runners as 'Advanced,' which is reflected in its low precision score for that class (it classified 5 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'Intermediate' runners as 'Advanced'). This may have occurred due to the similarity of some features in the data (e.g., Average HR, Distance) between the classes.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- <u>Second Method: Scikit-learn (SKL) Decision Tree</u>  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This model demonstrated the poorest performance on the test set and showed signs of being overfitted to the training data (train accuracy: 0.82, test accuracy: 0.60).  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Furthermore, the model was effective at identifying 'Beginner' runners but performed poorly on the other classes. We can infer that this occurred because the relatively &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;low pace of the 'Beginner' class allowed the model to find a 'pure' condition to separate the majority of 'Beginner' runners from the rest of the data.   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- <u>Third Method: Logistic Regression Model</u>  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This model demonstrated the best performance among all models tested. The key features in the regression equation were 'Calculated Pace' and 'Distance,' which led &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to excellent model performance across all metrics (including accuracy, recall, and precision). Additionally, the model performed consistently well across all classes.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- <u>Fourth Method: Random Forest</u>  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The proposed model demonstrated a marginal improvement in performance over a standard decision tree. The slightly reduced performance observed on the &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;training set is a key indicator that the model has avoided overfitting. This model, consistent with the behavior of other decision tree algorithms in this project, achieved &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;its highest performance metrics for the Beginner class.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- <u>Fifth Method: Gradient Boosting</u>  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The proposed model exhibited performance metrics nearly identical to those of the Random Forest model. It is important to note that the sample size is small, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;which means every single misclassification has a significant impact on the overall metrics.   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This model appears to rely heavily on the feature calculated pace. Both models achieved their highest performance metrics for the Beginner class.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Additionally, an analysis of the Advanced class performance suggests the model may have acquired a \"wrong\" heuristic during training that led to poorer results &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;on the test set, specifically in its ability to accurately classify this group.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**<u>General Conclusions</u>**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Overall, 'Calculated Pace' had the biggest influence on the classification results, which makes sense since the GRPS score (which determined the label of each runner) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;was based on the runner's pace (better runners will generally have a better pace).  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Although I initially thought it would have a more significant influence on the different models, 'Average Heart Rate' did not appear to be a significant factor in &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;determining the class of a runner.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;With that said, it has been the second most important feature in Random Forest and Gradient Boosting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b30531b-2348-424e-9ca1-8f06819941f2",
   "metadata": {},
   "source": [
    "**Clustering Method - using Kmeans clustering**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fedb3d-32d6-443a-9dab-9156b593c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features Scaling \n",
    "features = final_df.select_dtypes(include=[int, float])\n",
    "\n",
    "scaler=StandardScaler()\n",
    "normalized_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60cc784-3270-4c1d-89ba-6d5eec51ff0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#finding the best K with Interia, Silhouette\n",
    "os.environ['OMP_NUM_THREADS'] = '2'\n",
    "inertia_values = []\n",
    "max_k = 9\n",
    "k_range = range(1, max_k + 1, 2)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto') #runs the algorithm multiple times with different random initializations and picks the best one\n",
    "    kmeans.fit(normalized_features)\n",
    "    inertia_values.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertia_values, marker='o', linestyle='--')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia (Within-cluster Sum of Squares)')\n",
    "plt.xticks(k_range) \n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "silhouette_scores = []\n",
    "k_range_silhouette = range(2, max_k + 1)\n",
    "\n",
    "for k in k_range_silhouette:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    cluster_labels = kmeans.fit_predict(normalized_features)\n",
    "    score = silhouette_score(normalized_features, cluster_labels)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range_silhouette, silhouette_scores, marker='o', linestyle='--')\n",
    "plt.title('Silhouette Score for Optimal K')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.xticks(k_range_silhouette)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "db_scores = []\n",
    "max_k = 10\n",
    "k_range_db = range(2, max_k + 1)\n",
    "for k in k_range_db:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    cluster_labels = kmeans.fit_predict(normalized_features)\n",
    "    score = davies_bouldin_score(normalized_features, cluster_labels)\n",
    "    db_scores.append(score)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range_db, db_scores, marker='o', linestyle='--')\n",
    "plt.title('Davies-Bouldin Score for Optimal K')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Davies-Bouldin Score')\n",
    "plt.xticks(k_range_db)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce727b9-5366-46c5-972f-58bd0542220e",
   "metadata": {},
   "source": [
    "**The Elbow Method** - A method which helps us to choose the best number of centroids (k) in our model. The core idea behind the elbow method is that as you increase the number of clusters, the data points in each cluster will become closer to their respective cluster centroids. This will decrease the \"inertia,\" or the sum of squared distances, for all the clusters At some point, adding another cluster will not significantly reduce the inertia. This is the \"elbow\" of the curve, where the rate of decrease in inertia slows down dramatically. This \"elbow\" point is considered to be the optimal number of clusters. The goal of the Elbow Method is to find the point where this decrease in inertia is no longer worth the added complexity of another cluster.  \n",
    "\n",
    "When using the Silhouette score, the optimal number of clusters (K) is identified by the highest score, as this indicates well-separated and compact clusters.\n",
    "\n",
    "The Davies-Bouldin score graph shows a general trend of decreasing values as K increases. However, it can be observed that the value decreases most significantly at K=3. This value represents a balance between a low Davies-Bouldin score and the need to avoid overfitting with an excessive number of clusters.\n",
    "\n",
    "Based on these findings, K=3 is the optimal number of clusters. This is supported by two key pieces of evidence: it corresponds to the highest Silhouette score, and it is the point in the Elbow method where the rate of decrease in inertia begins to diminish, forming a clear \"elbow.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6deffef-025c-44c2-8369-726114b3018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(normalized_features)\n",
    "final_df[\"Cluster\"] =  cluster_labels\n",
    "sns.scatterplot(x=\"Median Calculated Pace\", y=\"Median Distance\", hue=\"Cluster\", data=final_df, palette=\"Set1\")\n",
    "plt.title(\"Clustering Runners by Performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19177561-52cc-40cf-a52b-ddc542dbb7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"Median Calculated Pace\", y=\"Median Avg HR\", hue=\"Cluster\", data=final_df, palette=\"Set1\")\n",
    "plt.title(\"Clustering Runners by Performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e74c36-58d8-4c56-95c3-d7539a86457d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimal_k = 3\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "sc = ax.scatter(final_df[\"Median Calculated Pace\"], final_df['Median Distance'], final_df['Median Avg HR'], c=final_df['Cluster'], cmap='viridis', s=50)\n",
    "plt.colorbar(sc)\n",
    "ax.set_xlabel('Median Calculated Pace')\n",
    "ax.set_ylabel('Median Distance')\n",
    "ax.set_zlabel('Median Avg HR')\n",
    "ax.set_title('3D Cluster Visualization')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285bc52a-58ea-43b4-aed7-37df13ee511e",
   "metadata": {},
   "source": [
    "**Kmeans Conclusion**  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;- We can see that the clustering provided clusters with the next characteristics:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<u>Cluster 0</u> - Low pace runners, distance is wide-spreaded (our 'Beginners')  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<u>Cluster 1</u> - Medium to high pace ruuners, longer distances (our 'Advanced')  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<u>Cluster 2</u> - Medium to high pace runners, short distances (our 'Intermediate')  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- The analysis of the cluster's characteristics suggests that average heart rate was not a primary factor in the formation of the clusters.  A consistent range of average &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;heart rates is observed across all clusters, indicating a uniform distribution of this feature. This finding is reinforced by the fact that the majority of runners have an &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;average heart rate between 130 and 165 BPM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d1c53-145c-4088-8cf1-b42944493629",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.loc[final_df[\"Runner\"] == \"maor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b32a1f6-6e27-4a44-b957-5cf75a998655",
   "metadata": {},
   "source": [
    "**Example** - Based on the clustering we've processed I belong to cluster 1 which makes me a medium to high pace runner for long distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1e2f3c-847c-475c-858d-9f9c5a2fcbf7",
   "metadata": {},
   "source": [
    "**Using ARI and V-measure to compare the clusters to our initial GRPS classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7949c331-ba77-4410-8c2b-c9c61703f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\"Beginner\": 0,\"Intermediate\": 2, \"Advanced\": 1}\n",
    "final_df[\"Runner_Class_Numeric\"] = final_df[\"Runner_Class\"].map(class_mapping)\n",
    "labels_true = final_df.loc[:, \"Runner_Class_Numeric\"]\n",
    "labels_pred = final_df.loc[:, \"Cluster\"]\n",
    "ari_score = adjusted_rand_score(labels_true, labels_pred)\n",
    "print(f\"Perfect match ARI score: {ari_score:.2f}\")\n",
    "v_score = v_measure_score(labels_true, labels_pred)\n",
    "print(f\"Perfect match V-measure score: {v_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b790f-615f-434f-9a28-35aaae72eacf",
   "metadata": {},
   "source": [
    "We can see that the ARI is 0.2 and the V-measure is 0.28 which aren't great values. It may show that the Kmeans model found  patterns in our data which are different from the way we have decided to label our runner. It also can happen because the features used for clustering may not be the most significant ones for distinguishing between the runner classes as we defined them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0898914-f62a-4076-b023-106ca4e322ee",
   "metadata": {},
   "source": [
    "**Final conclusions**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ead0b-81a0-4ac2-8be2-4e6359702cbe",
   "metadata": {},
   "source": [
    "In this project I explored the problem of classifying runners into performance tiers using personal running data, common runing metrics (pace, distance, heart rate etc.) and a derived General Running Performance Score (GRPS) which is primarly based on Reigel formula.  \n",
    "\n",
    "I tested unsupervised clustering model (KMeans) and supervised models (Decision tree ,Logistic Regression, Random Forest, Gradient Boosting) and evaluated models using stratified cross-validation and a held-out test set.  \n",
    "\n",
    "The best performing classification models balanced precision and recall across the three classes, however, adjacent classes (Beginner vs Intermediate and Intermediate vs Advanced) remain the primary source of error, reflecting realistic overlap in runner abilities.\n",
    "\n",
    "Feature-importance analysis showed that normalized pace was the most predictive feature to classify our runners based on the method we used to determine the labels (based on their GRPS score).  \n",
    "\n",
    "We also learned that our clustering model found diferrent patterns in the data than the labels we've had determined.\n",
    "\n",
    "Overall, the project demonstrates a full end-to-end pipeline - data collection, feature engineering (GRPS metric), exploratory analysis, modeling based on multiple classification approaches and clustering , evaluation and has a touch to my daily areas of intrest. With a larger dataset and final polish on conclusions, it can stand out as a solid applied Data Science project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
